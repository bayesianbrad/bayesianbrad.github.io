---
layout: post
title:  "An Introduction to Hamiltonian Monte Carlo "
date:   2018-04-4 14:06:00
categories: Notes MCMC Python
author: Bradley
comments: true
---
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML.js"></script>

In this post I will go through a powerful MCMC algorithm called Hamiltonian Monte Carlo (HMC) and demonstrate how to implement the algorithm within the [pytorch](http://pytorch.org/) framework. 


Let us start with a  super nice gif demonstrating the conservation of momentum in action:
<p><img src="https://www.wired.com/images_blogs/wiredscience/2011/10/ball_2.gif" alt="momentum"
	title="The conservation of momentum in action" width="550" height="250" /></p>


## The Hamiltonian

The Hamiltonian of a physical system is defined completely with respect to the position $$x$$ and $$p$$ momentum variables, which span the phase space of the system. The Hamiltonian is the Legendre transform of the Lagrangian and gives us the total energy in the system. It is defined as follows: 
\begin{equation}
\label{one}\tag{1}
 H(x,p) = \sum_{i = 1}^{d}\dot{x}_l p_l - L(x, \dot{x}(x, p))
\end{equation}
where $$d$$ is the system dimensions, and so the full state space with has $$2d$$ dimensions.
Thus, for simplicity, if we set $$d = 1$$ we can derive the Hamiltonian equations as follows:
\begin{equation}
\label{hameq1}\tag{2}
\frac{\partial H}{\partial p} = \dot{x} + p\frac{\partial \dot{x}}{\partial p} - \frac{\partial L}{\partial \dot{x}}\frac{\partial \dot{x}}{\partial p} = \dot{x} 
\end{equation}
and 
\begin{equation}
\label{hameq2}\tag{3}
\frac{\partial H}{\partial x} = p\frac{\partial \dot{x}}{\partial x} - \frac{\partial L}{\partial x} - \frac{\partial L}{\partial \dot{x}}\frac{\partial \dot{x}}{\partial x} = - \frac{\partial L}{\partial x}= -\dot{p}  
\end{equation}

and the process is the same for more than one dimension, you just set $$d=n$$ ;-). 
We can write \eqref{one} more succinctly as:
\begin{equation}
\label{hamreduced}\tag{4}
H(x, p)  = K(p) + U(x)
\end{equation}

where $$K(p)$$ represents our kinetic energy and $$U(x)$$ is the potential energy.

Within the HMC MCMC framework the ''positions", $$x$$, are the variables of interest and for each position variable we have to create a fictitious ''momentum", $$p$$. For compactness let $$z = (x,p)$$. The potential energy $$U(x)$$ will be the minus of the log of the probability density for the distribution of the position variables we wish to sample, plus \textbf{any} constant that is convenient.  The kinetic energy will represents the dynamics of our variables, for which a popular form of $$K(p) = \frac{p^{T} M^{-1} p}{2}$$, where $$M$$ is symmetric, positive definite and typically diagonal. This form of $$K(p)$$ corresponds to a minus the log probability of the zero mean Gaussian distribution with covariance matrix $$M$$. For this choice we can write the Hamiltonian equations, for any dimension $$d$$, as follows:
<p>
$$\begin{align}
\dot{x}_{i} &= \frac{dx_{i}}{dt} = [M^{-1}p]_{i} \label{position}\tag{5}\\ 
\dot{p}_{i} &= \frac{dp_{i}}{dt} = -\frac{\partial U}{\partial q_{i}} \label{momentum}\tag{6}
\end{align}$$
</p>
To view the Hamiltonian in terms of probabilities, we use the concept of the canonical distribution from Statistical mechanics to construct our pdf. Thus, the distribution that we wish to sample from can be related to the potential energy via the canonical distribution as:
\begin{equation}
\label{canonical}\tag{7}
P(z) = \frac{1}{Z}\exp\left(\frac{-E(z)}{T}\right)
\end{equation}
As the Hamiltonian is just an energy function we may can insert \eqref{hamreduced} into our canonical distribution \eqref{canonical}, which gives us the joint density:
\begin{equation}
\tag{8}
P(x,p) = \frac{1}{Z}\exp(-U(x))\exp(-K(p)) 
\end{equation}

where $$T = 1$$ is fixed. And so we can now very easily get to our target distribution $$p(x)$$, which is dependent on our choice of potential $$U(x)$$, as this expression factorizes in to two independent probability distributions. 
We characterise the posterior distribution for the model parameters using the potential energy function: 
\begin{equation}
\tag{9}
U(x) = -\log[p(x)p(x|D)]
\end{equation}
where $$p(x)$$ is the prior distribution, and $$p(x|D)$$ is the likelihood, not the Lagrangian, of the given data $$D$$. 

## Solving Hamilton's Equations

In order to solve the set of differential equations generated from Hamilton's formalism we need to integrate. If the potential function (joint density in the MCMC framework) is well understood, then it maybe possible to solve the Hamilton's equations analytically. However, in many instances in both the physical and MCMC framework you have functions that generate integrals that are impossible to solve analytically using known techniques. 
A resolution to this is to employ numerical methods, which enable to produce an approximation that is close to the true value.
However, to implement numerical solver requires us to discretize Hamilton's equations. This induces errors.

One could employ Euler's method for solving a series of differential equations, however, it has less than desirable properties in regards to the local and global errors incurred in the approximation. Where local error, is the error after one step and global error, is the error after simulating for some fixed time interval. A more optimal integrator is the Leapfrog integrator, that has a local error of $$\mathcal{O}(\epsilon^{2})$$ and a global error of $$\mathcal{O}(\epsilon^{3})$$

### The Leapfrog Integrator

The leapfrog integrator has properties that ensure that both global and local errors remain small. In addition to this, they  and allows us to dicretize Hamiltons equations
We start with a state at $$t = 0$$ and then evaluate at a subsequent time $$t + \epsilon , \ldots, t + n\epsilon$$, where $$\epsilon$$ is the step in which we increase and $$n$$ is the number of time steps. 
<p>
$$\begin{align}
p_{i}(t + \frac{\epsilon}{2}) &= p_{i}(t) - \left(\frac{\epsilon}{2}\right)\frac{\partial U(x(t))}{\partial x_{i}} \tag{10} \\
x_{i}(t + \epsilon) &= x_{i}(t) + \epsilon\frac{\partial K(p(t + \frac{\epsilon}{2}))}{dp_{i}} \tag{11}\\

p_{i}(t + \epsilon) &= p_{i}(t + \frac{\epsilon}{2}) - \left(\frac{\epsilon}{2}\right)\frac{\partial U}{\partial x_{i}} \tag{12}\\
\end{align}$$
</p>
For the usual choice of kinetic energy, we have $$\frac{\partial K(p + \frac{\epsilon}{2})}{dp_{i}} = \frac{p_{i}(t + \frac{\epsilon}{2})}{m_{i}}$$


### Some initial points of notice

Neals implementation of the HMC can only be used to sample from continuous distributions on $$\mathbb{R}^{d}$$ for which a density function can be evaluated.\\
We must be able to compute the partial derivative of the log of the density function. The derivatives must exists at the points at which they are evaluated.

HMC samples from the canonical distribution for $$x$$ and $$p$$. $$x$$ has the distribution of interest as specified by the potential $$U(x)$$. 
The distribution of the $$p$$'s can be chosen by us and are independent of the $$x$$'s. 
The $$p$$ components are specified to be independent, with component $$p_{i}$$ having variance $$m_{i}$$.
The kinetic energy $$K(p) = \sum_{i =1}^{d}\frac{p_{i}^{2}}{2m_{i}}(x(t + \epsilon))$$. It should be noted that you can use different kinetics energies and these will all have varying effects, see [here](https://arxiv.org/abs/1706.02649) for more details. The standard kinetic energy actually has a direct link to the Gaussian distribution, and can be seen as average energy over all states. This is linked to the Boltzmann distribution in statistical physics, see [here](http://hyperphysics.phy-astr.gsu.edu/hbase/Kinetic/molke.html) for more details.


## The Hamilton Monte Carlo Algorithm

![png](/assets/posts/2018_hmc/hmc.png)

## How to Implement HMC in a System
I'm going slightly exaggerate some aspects of the code, so that it is clear how one can implement HMC more generally and if needed, for research purposes, add your own HMC flavor. Disclaimer: This code is not optimised for speed, it is here for readability and clarity. 
I should also note, that once `Pytorch 0.4` has been released, all `Variable` statements can be replaced with `torch.tensor(data=...)` and if you want the gradients of those objects, then you do `torch.tensor(data=... , dtype=..., requires_grad=True)`
We are going to use a helper function for now called `VariableCast()`, for `Pytorch v0.3` and lower, which handles this automatically:

```python
    import torch
    from torch.autograd.variable import Variable
    def VariableCast(value, grad = False):
        '''
        Casts an input to torch Variable object, with gradients either False or True. 
        input
        -----
        value - Type: scalar, Variable object, torch.Tensor, numpy ndarray
        grad  - Type: bool . If true then we require the gradient of that object
        output
        ------
        torch.autograd.variable.Variable object
        '''
        if value is None:
            return None
        elif isinstance(value, Variable):
            return value
        elif torch.is_tensor(value):
            return Variable(value, requires_grad = grad)
        elif isinstance(value, np.ndarray):
            tensor = torch.from_numpy(value).float()
            return Variable(tensor, requires_grad = grad)
        elif isinstance(value,list):
            return Variable(torch.FloatTensor(value), requires_grad=grad)
        else:
            return Variable(torch.FloatTensor([value]), requires_grad = grad)
```

## Step 1
### The Integrator

```python
    #!/usr/bin/env python3
    # -*- coding: utf-8 -*-
    import torch
    import numpy as np
    from kinetic import Kinetic
    from torch.autograd import Variable

    class Integrator():

        def __init__(self, potential, min_step, max_step, max_traj, min_traj):
            self.potential = potential
            if min_step is None:
                self.min_step = np.random.uniform(0.01, 0.07)
            else:
                self.min_step = min_step
            if max_step is None:
                self.max_step = np.random.uniform(0.07, 0.18)
            else:
                self.max_step = max_step
            if max_traj is None:
                self.max_traj = np.random.uniform(18, 25)
            else:
                self.max_traj = max_traj
            if min_traj is None:
                self.min_traj = np.random.uniform(1, 18)
            else:
                self.min_traj = min_traj

        def generate_new_step_traj(self):
            ''' Generates a new step adn trajectory size  '''
            step_size = np.random.uniform(self.min_step, self.max_step)
            traj_size = int(np.random.uniform(self.min_traj, self.max_traj))
            return step_size, traj_size


        def leapfrog(self, p_init, x, grad_init):
            '''Performs the leapfrog steps of the HMC for the specified trajectory
            length, given by num_steps
            Parameters
            ----------
                values_init
                p_init
                grad_init     - Description: contains the initial gradients of the joint w.r.t parameters.

            Outputs
            -------
                x -    Description: proposed new x
                p      -    Description: proposed new auxillary momentum
            '''
            step_size, traj_size = self.generate_new_step_traj()
            values_init = x
            self.kinetic = Kinetic(p_init)
            # Start by updating the momentum a half-step and x by a full step
            p = p_init + 0.5 * step_size * grad_init
            x = values_init + step_size * self.kinetic.gauss_ke(p, grad=True)
            for i in range(traj_size - 1):
                # range equiv to [2:nsteps] as we have already performed the first step
                # update momentum
                p = p + step_size * self.potential.eval(x, grad=True)
                # update x
                x = x + step_size * self.kinetic.gauss_ke(p, grad=True)

            # Do a final update of the momentum for a half step
            p = p + 0.5 * step_size * self.potential.eval(x, grad=True)
            # print('Debug p, vlaues leapfrog', p, x)

            # return new proposal state
            return x, p
```
### Kinetic Energy

```python
    from core import VariableCast
    import torch
    from torch.autograd import Variable
    class Kinetic():
        ''' A basic class that implements kinetic energies and computes gradients
        Methods
        -------
        gauss_ke          : Returns KE gauss
        laplace_ke        : Returns KE laplace

        Attributes
        ----------
        p    - Type       : torch.Tensor, torch.autograd.Variable,nparray
            Size       : [1, ... , N]
            Description: Vector of current momentum

        M    - Type       : torch.Tensor, torch.autograd.Variable, nparray
            Size       : \mathbb{R}^{N \times N}
            Description: The mass matrix, defaults to identity.

        '''
        def __init__(self, p, M = None):

            if M is not None:
                if isinstance(M, Variable):
                    self.M  = VariableCast(torch.inverse(M.data))
                else:
                    self.M  = VariableCast(torch.inverse(M))
            else:
                self.M  = VariableCast(torch.eye(p.size()[0])) # inverse of identity is identity


        def gauss_ke(self,p, grad = False):
            '''' (p dot p) / 2 and Mass matrix M = \mathbb{I}_{dim,dim}'''
            self.p = VariableCast(p)
            P = Variable(self.p.data, requires_grad=True)
            K = 0.5 * P.t().mm(self.M).mm(P)

            if grad:
                return self.ke_gradients(P, K)
            else:
                return K
        def laplace_ke(self, p, grad = False):
            self.p = VariableCast(p)
            P = Variable(self.p.data, requires_grad=True)
            K = torch.sign(P).mm(self.M)
            if grad:
                return self.ke_gradients(P, K)
            else:
                return K
        def ke_gradients(self, P, K):
            return torch.autograd.grad([K], [P])[0]
```

### Potential Energy
*Step 1* 
Automatically calculating the gradients for an arbitrary function might sound difficult, but with any auto differentiation framework this is actually quite trivial. 
In `Pytorch` we can do the following:
```python
    def _grad_logp(self, logp, values):
        """
        Returns the gradient of the log pdf, with respect for
        each parameter

        Parameters
        ----------
        logjoint       - 
        values         - All parameters for which you need gradients.
    
        :return: torch.autograd.Variable
        """

        gradient_of_param = torch.autograd.grad(outputs=logp, inputs=values, retain_graph=True)[0]
        return gradient_of_param
```
### Metropolis Step
```python
    import torch
    from torch.autograd import Variable
    from Utils.kinetic import Kinetic

    class Metropolis():

        def __init__(self, potential, integrator, M):
            self.potential  = potential
            self.integrator = integrator
            self.M          = M
            self.count      = 0

        def sample_momentum(self,values):
            assert(isinstance(values, Variable))
            return Variable(torch.randn(values.data.size()))

        def hamiltonian(self, logjoint, p):
            """Computes the Hamiltonian  given the current postion and momentum
            H = U(x) + K(p)
            U is the potential energy and is = -log_posterior(x)
            Parameters
            ----------
            logjoint    - Type:torch.autograd.Variable
                        Size: \mathbb{R}^{1 \times D}
            p           - Type: torch.Tensor.Variable
                        Size: \mathbb{R}^{1 \times D}.
                        Description: Auxiliary momentum
            log_potential :Function from state to position to 'energy'= -log_posterior

            Returns
            -------
            hamitonian : float
            """
            T = self.kinetic.gauss_ke(p, grad=False)
            return -logjoint + T
        def acceptance(self, values_init, logjoint_init, grad_init):
            '''Returns the new accepted state

            Parameters
            ----------

            Output
            ------
            returns accepted or rejected proposal
            '''

            # generate initial momentum

            #### FLAG
            p_init = self.sample_momentum(values_init)
            # generate kinetic energy object.
            self.kinetic = Kinetic(p_init, self.M)
            # calc hamiltonian  on initial state
            orig = self.hamiltonian(logjoint_init, p_init)

            # generate proposals
            values, p = self.integrator.leapfrog(p_init, values_init, grad_init)

            # calculate new hamiltonian given current
            logjoint_prop, _ = self.potential.eval(values, grad=False)

            current = self.hamiltonian(logjoint_prop, p)
            alpha = torch.min(torch.exp(orig - current))
            # calculate acceptance probability
            if isinstance(alpha, Variable):
                p_accept = torch.min(torch.ones(1, 1), alpha.data)
            else:
                p_accept = torch.min(torch.ones(1, 1), alpha)
            # print(p_accept)
            if p_accept[0][0] > torch.Tensor(1, 1).uniform_()[0][0]:  # [0][0] dirty code to get integersr
                # Updates count globally for target acceptance rate
                # print('Debug : Accept')
                # print('Debug : Count ', self.count)
                self.count = self.count + 1
                return values, self.count
            else:
                # print('Debug : reject')
                return values_init, self.count
```
### Tying Everything Together


```python
    import torch
    import numpy as np
    import time
    import math
    from torch.autograd import Variable
    from Utils.integrator import Integrator
    from Utils.metropolis_step import Metropolis
    # np.random.seed(12345)
    # torch.manual_seed(12345)
    class HMCsampler():
        '''
        Notes:  the params from FOPPL graph will have to all be passed to - maybe
        Methods
        -------
        leapfrog_step - preforms the integrator step in HMC
        hamiltonian   - calculates the value of hamiltonian
        acceptance    - calculates the acceptance probability
        run_sampler

        Attributes
        ----------

        '''
        def __init__(self, program, burn_in= 100, n_samples= 20000, M= None,  min_step= None, max_step= None,\
                    min_traj= None, max_traj= None):
            self.burn_in    = burn_in
            self.n_samples  = n_samples
            self.M          = M
            self.potential  = program()
            self.integrator = Integrator(self.potential, min_step, max_step, \
                                        min_traj, max_traj)
            # self.dim        = dim

            # TO DO : Implement a adaptive step size tuning from HMC
            # TO DO : Have a desired target acceptance ratio
            # TO DO : Implement a adaptive trajectory size from HMC


        def run_sampler(self):
            ''' Runs the hmc internally for a number of samples and updates
            our parameters of interest internally
            Parameters
            ----------
            n_samples
            burn_in

            Output
            ----------
            A tensor of the number of required samples
            Acceptance rate
            '''
            print(' The sampler is now running')
            # In the future dim = # of variables will not be needed as Yuan will provide
            # that value in the program and it shall return the required dim.
            logjoint_init, values_init, grad_init, dim = self.potential.generate()
            metropolis   = Metropolis(self.potential, self.integrator, self.M)
            temp,count   = metropolis.acceptance(values_init, logjoint_init, grad_init)
            samples      = Variable(torch.zeros(self.n_samples,dim))
            samples[0]   = temp.data.t()


            # Then run for loop from 2:n_samples
            for i in range(self.n_samples-1):
                logjoint_init, grad_init = self.potential.eval(temp, grad_loop= True)
                temp, count = metropolis.acceptance(temp, logjoint_init, grad_init)
                samples[i + 1, :] = temp.data.t()
                # try:
                #     samples[i+1,:] = temp.data.t()
                # except RuntimeError:
                #     print(i)
                #     break
                # update parameters and draw new momentum
                if i == np.floor(self.n_samples/4) or i == np.floor(self.n_samples/2) or i == np.floor(3*self.n_samples/4):
                    print(' At interation {}'.format(i))

            # Basic summary statistics
            target_acceptance =  count / (self.n_samples)
            samples_reduced   = samples[self.burn_in:, :]
            mean = torch.mean(samples_reduced,dim=0, keepdim= True)
            print()
            print('****** EMPIRICAL MEAN/COV USING HMC ******')
            print('empirical mean : ', mean)
            print('Average acceptance rate is: ', target_acceptance)

            return samples,samples_reduced, mean
```
